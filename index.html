<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Paras Jain - Machine Learning Engineer</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <header>
        <h1>Paras Jain</h1>
        <p>Machine Learning Engineer</p>
        <img src="ParasUpdatedImage.jpg" alt="Profile Picture">
    </header>
    <main>
        <section id="about">
            <h2>About Me</h2>
            <p>Rochester, NY | +1 (585) 576-1904 | <a href="mailto:parasjain1999@gmail.com">parasjain1999@gmail.com</a> | <a href="https://www.linkedin.com/in/paras-jain99/">LinkedIn</a> | <a href="https://github.com/Jainparas99">GitHub</a></p>
        </section>
        <section id="education">
            <h2>Education</h2>
            <ul>
                <li>
                    <h3>M.S. in Artificial Intelligence, Rochester Institute of Technology</h3>
                    <p>GPA: 3.9/4.0, Aug 2023 - May 2025</p>
                    <p>Courses: High-Performance Architecture, Robotics Software Systems, Computer Vision, Machine Learning, CUDA</p>
                </li>
                <li>
                    <h3>B. Tech in Computer Science, SRM Institute of Science and Technology</h3>
                    <p>GPA: 8.5/10.0, July 2017 - May 2021</p>
                </li>
            </ul>
        </section>
        <section id="skills">
            <h2>Skills and Technologies</h2>
            <ul>
                <li>Programming Languages: Python, C++, C, Bash, R, SQL</li>
                <li>ML/AI Frameworks: PyTorch, TensorFlow, Hugging Face, Scikit-learn, Lang Chain, OpenCV, CUDA</li>
                <li>Cloud & Tools: Azure ML, AWS, Fast API, Git, Jenkins, FAISS, Tru Lens, Deep Eval, MongoDB, VLM</li>
                <li>Core Expertise: Machine Learning, Deep Learning, Computer Vision, LLM Evaluation, NLP, Reinforcement Learning</li>
            </ul>
        </section>
        <section id="work-experience">
            <h2>Work Experience</h2>
            <ul>
                <li>
                    <h3>AI Intern, NetApp</h3>
                    <p>May 2024 – Dec 2024</p>
                    <ul>
                        <li>Built a RAG-based chatbot system integrating FAISS vector search with OpenAI LLMs, achieving accurate document-grounded Q&A with zero hallucination on internal knowledge base</li>
                        <li>Deployed Azure ML-powered Auto ML pipelines for ARR forecasting, achieving over 95% accuracy on quarterly revenue predictions using time series analysis and feature engineering</li>
                    </ul>
                </li>
                <li>
                    <h3>Software Developer, Barclays</h3>
                    <p>Aug 2021 – Aug 2023</p>
                    <ul>
                        <li>Built ETL screening engine for Anti-Money Laundering (AML) detection, improving accuracy by 25% through data quality optimization and feature engineering</li>
                    </ul>
                </li>
            </ul>
        </section>
        <section id="academic-projects">
            <h2>Academic Projects</h2>
            <ul>
                <li>
                    <h3>High-Resolution Segmentation via SAM and Super-Resolution</h3>
                    <p>Sep 2024 – Dec 2024</p>
                    <ul>
                        <li>Augmented Meta’s Segment Anything Model (SAM) with a Laplacian pyramid-based super-resolution module to enhance spatial fidelity and improve semantic segmentation performance under degraded visual inputs.</li>
                        <li>Integrated a multi-stage pipeline where high-frequency reconstruction preceded segmentation, enabling sharper attention map focus across the encoder-decoder transformer backbone.</li>
                        <li>Quantitatively benchmarked using IoU, Dice, and pixel-wise F1 metrics, showing up to +12% gain in boundary-sensitive segmentation tasks.</li>
                    </ul>
                </li>
                <li>
                    <h3>Atrial Fibrillation Detection Using Transformer Models on ECG Signals</h3>
                    <p>Dec 2020 – May 2021</p>
                    <ul>
                        <li>Built a deep learning pipeline using Transformer encoders to classify Atrial Fibrillation episodes directly from long-duration 1D ECG signals, leveraging temporal attention to capture irregular heartbeat patterns.</li>
                        <li>Preprocessed biomedical time-series data into normalized and windowed signal segments using sliding windows aligned with AFib annotations.</li>
                        <li>Trained models on multiple patients’ ECG recordings using label-balanced sampling and positional encoding, achieving high classification performance with low false positives.</li>
                        <li>Demonstrates expertise in sequence modeling, time-series, transformer architectures, and biomedical ML.</li>
                    </ul>
                </li>
                <li>
                    <h3>CUDA Kernel Optimization for VGG16</h3>
                    <p>Jan 2025 – May 2025</p>
                    <ul>
                        <li>Architected custom CUDA C++ kernels implementing shared memory tiling, coalesced memory access, and thread block-level parallelism for 2D convolutional layers from VGG16.</li>
                        <li>Achieved up to 7× speedup over naive GPU implementations, validated against PyTorch ONNX inference outputs for L2-norm error stability.</li>
                        <li>Analyzed memory throughput using CUDA profiler (Nsight) and optimized kernel occupancy through loop unrolling and bank conflict minimization.</li>
                        <li>Demonstrates deep competency in model-level hardware acceleration, GPU-bound CV workloads, and on-device neural inference optimization, critical for edge-based XR rendering.</li>
                    </ul>
                </li>
                <li>
                    <h3>Indic OCR Enhancement Using Vision-Language Model Fine-Tuning</h3>
                    <p>Feb 2024 – Apr 2024</p>
                    <ul>
                        <li>Fine-tuned Qwen2-VL, a multimodal vision-language transformer, for low-resource Gujarati OCR, using a custom dataset comprising scanned documents and native script annotations.</li>
                        <li>Preprocessed image inputs with OpenCV morphological operations and Real-ESRGAN for resolution recovery, improving input clarity under noisy scan conditions.</li>
                        <li>Evaluated with WER (Word Error Rate) and CER (Character Error Rate), achieving significant reductions post-enhancement.</li>
                        <li>Demonstrates capability in ground truth dataset generation, multilingual vision-language fine-tuning, OCR pipeline curation, and low-resource domain adaptation directly aligned with spatial AI localization and meta-linguistic modeling.</li>
                    </ul>
                </li>
                <li>
                    <h3>Facial Emotion Recognition via Landmark-Guided CNNs (Published)</h3>
                    <p>Dec 2020 – May 2021</p>
                    <ul>
                        <li>Developed a facial effect classification pipeline using statistically normalized landmark-based ROI extraction and a compact CNN classifier optimized for real-time inference.</li>
                        <li-Conducted model interpretability via Grad-CAM activation mapping and compared performance across FER2013 and custom annotated subsets.</li>
                        <li>Published results in an IEEE venue, emphasizing generalizability and label alignment robustness across cultural expression variances.</li>
                    </ul>
                </li>
    <!-- Add more academic projects here -->
            </ul>
        </section>
        <section id="publications">
            <h2>Publications</h2>
            <ul>
                <li>
                    <h3>Face Emotion Detection Using Deep Learning</h3>
                    <p>2021 Fifth International Conference on I-SMAC (IoT in Social, Mobile, Analytics and Cloud) (I-SMAC), Palladam, India, 2021, pp. 517-522, doi: 10.1109/I-SMAC52330.2021.9641053</p>
                </li>
                <li>
                    <h3>Human Machine Confidence Comparison</h3>
                    <p>IEEE CogMI (Under Review, June 2025)</p>
                </li>
            </ul>
        </section>
    </main>
</body>
</html>